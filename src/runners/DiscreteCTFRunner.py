import torch
import logging
from time import time
from utils import utils
from utils.global_p import *
from tqdm import tqdm
import gc
import numpy as np
import copy
import os
from runners.BaseRunner import BaseRunner


class DiscreteCTFRunner(BaseRunner):
    def parse_ctf_runner_args(parser):
        
        parser.add_argument('--ctf_load', type=int, default=0,
                            help='Whether load model with ctf_load and continue to train')
        parser.add_argument('--ctf_train', type=int, default=1,
                            help='Whether train model with ctf_load')
        parser.add_argument('--epsilon1', type=float, default=0.0,
                            help='The accepted error for counterfactual constraints')
        parser.add_argument('--cc_weight', type=float, default=0.1,
                            help='The weight of counterfactual constraint')
        return parser
    
    def __init__(self, epsilon1, cc_weight, *args, **kwargs):
        
        self.epsilon1 = epsilon1 # control how rigorous is the constraint
        self.cc_weight = cc_weight # weight of counterfactual constraint loss
        BaseRunner.__init__(self, *args, **kwargs)
        
    def fit(self, model, data, data_processor, epoch=-1):  # fit the results for an input set
        """
        training
        :param model: model
        :param data: data dictï¼Œgenerated by self.get_*_data() and self.format_data_dict() from DataProcessor
        :param data_processor: DataProcessor instant
        :param epoch: epoch number
        :return: return output of last epoch, could provide self.check to check intermediate results.
        """
        gc.collect()
        if model.optimizer is None:
            model.optimizer = self._build_optimizer(model)
        batches = data_processor.prepare_batches(data, self.batch_size, train=True, model=model)
        batches = self.batches_add_control(batches, train=True)
        if self.pre_gpu == 1:
            batches = [data_processor.batch_to_gpu(b) for b in batches]

        batch_size = self.batch_size if data_processor.rank == 0 else self.batch_size * 2
        model.train()
        accumulate_size, prediction_list, output_dict = 0, [], None
        loss_list, loss_l2_list = [], []
        for i, batch in \
                tqdm(list(enumerate(batches)), leave=False, desc='Epoch %5d' % (epoch + 1), ncols=100, mininterval=1):
            if self.pre_gpu == 0:
                batch = data_processor.batch_to_gpu(batch)
            accumulate_size += len(batch[Y])
            model.optimizer.zero_grad()
            if model.data_processor == 'nonSeqCTFGenerator':
                output_dict = model(batch)
            else:
                output_dict = model(batch, data_processor.ctf_num, False)
            l2 = output_dict[LOSS_L2]
            loss = output_dict[LOSS] + l2 * self.l2s_weight
            for ctf_pred in output_dict[CTF_PREDICTION]:
                loss += self.cc_weight * torch.norm(torch.max(torch.zeros_like(output_dict[PREDICTION]), (output_dict[PREDICTION] - ctf_pred).abs() - self.epsilon1))
            loss.backward()
            loss_list.append(loss.detach().cpu().data.numpy())
            loss_l2_list.append(l2.detach().cpu().data.numpy())
            prediction_list.append(output_dict[PREDICTION].detach().cpu().data.numpy()[:batch[REAL_BATCH_SIZE]])
            if self.grad_clip > 0:
                # torch.nn.utils.clip_grad_norm_(model.parameters(), 100)
                torch.nn.utils.clip_grad_value_(model.parameters(), self.grad_clip)
            if accumulate_size >= batch_size or i == len(batches) - 1:
                model.optimizer.step()
                accumulate_size = 0
            # model.optimizer.step()
        model.eval()
        gc.collect()

        predictions = np.concatenate(prediction_list)
        sample_ids = np.concatenate([b[SAMPLE_ID][:b[REAL_BATCH_SIZE]] for b in batches])
        reorder_dict = dict(zip(sample_ids, predictions))
        predictions = np.array([reorder_dict[i] for i in data[SAMPLE_ID]])
        return predictions, output_dict, np.mean(loss_list), np.mean(loss_l2_list)
    
    def train(self, model, data_processor, old_runner, old_data_processor):
        """
        train the model
        :param model: model
        :param data_processor: DataProcessor
        :return:
        """

        # get data, no shuffle when epoch=-1
        train_data = data_processor.get_train_data(epoch=-1, model=model, runner=old_runner, processor=old_data_processor)
        validation_data = data_processor.get_validation_data(model=model)
        test_data = data_processor.get_test_data(model=model) if data_processor.unlabel_test == 0 else None
        self._check_time(start=True)  # record start time

        # evaluation before training
        init_train = self.evaluate(model, train_data, data_processor) \
            if train_data is not None else [-1.0] * len(self.metrics)
        init_valid = self.evaluate(model, validation_data, data_processor) \
            if validation_data is not None else [-1.0] * len(self.metrics)
        init_test = self.evaluate(model, test_data, data_processor) \
            if test_data is not None and data_processor.unlabel_test == 0 else [-1.0] * len(self.metrics)
        logging.info("Init: \t train= %s validation= %s test= %s [%.1f s] " % (
            utils.format_metric(init_train), utils.format_metric(init_valid), utils.format_metric(init_test),
            self._check_time()) + ','.join(self.metrics))
        # model.save_model(
        #     model_path='../model/variable_tsne_logic_epoch/variable_tsne_logic_epoch_0.pt')
        try:
            for epoch in range(self.epoch):
                self._check_time()
                # get training data for each epoch, since it involves shuffle or needs negative sampling
                epoch_train_data = data_processor.get_train_data(epoch=epoch, model=model, runner=old_runner, processor=old_data_processor)
                train_predictions, last_batch, mean_loss, mean_loss_l2 = \
                    self.fit(model, epoch_train_data, data_processor, epoch=epoch)

                # check intermediate results
                if self.check_epoch > 0 and (epoch == 1 or epoch % self.check_epoch == 0):
                    last_batch['mean_loss'] = mean_loss
                    last_batch['mean_loss_l2'] = mean_loss_l2
                    self.check(model, last_batch)
                training_time = self._check_time()

                # # evaluate model performance
                train_result = [mean_loss] + model.evaluate_method(train_predictions, train_data, metrics=['rmse'])
                valid_result = self.evaluate(model, validation_data, data_processor) \
                    if validation_data is not None else [-1.0] * len(self.metrics)
                test_result = self.evaluate(model, test_data, data_processor) \
                    if test_data is not None and data_processor.unlabel_test == 0 else [-1.0] * len(self.metrics)
                testing_time = self._check_time()

                self.train_results.append(train_result)
                self.valid_results.append(valid_result)
                self.test_results.append(test_result)

                # print out current performance
                logging.info("Epoch %5d [%.1f s]\t train= %s validation= %s test= %s [%.1f s] "
                             % (epoch + 1, training_time, utils.format_metric(train_result),
                                utils.format_metric(valid_result), utils.format_metric(test_result),
                                testing_time) + ','.join(self.metrics))

                # if current performance is the best, save the model, based on validation
                if utils.best_result(self.metrics[0], self.valid_results) == self.valid_results[-1]:
                    model.save_model()
                # model.save_model(
                #     model_path='../model/variable_tsne_logic_epoch/variable_tsne_logic_epoch_%d.pt' % (epoch + 1))
                # check whether early stop, based on validation
                if self.eva_termination(model) and self.early_stop == 1:
                    logging.info("Early stop at %d based on validation result." % (epoch + 1))
                    break
        except KeyboardInterrupt:
            logging.info("Early stop manually")
            save_here = input("Save here? (1/0) (default 0):")
            if str(save_here).lower().startswith('1'):
                model.save_model()

        # Find the best validation result across iterations
        best_valid_score = utils.best_result(self.metrics[0], self.valid_results)
        best_epoch = self.valid_results.index(best_valid_score)
        logging.info("Best Iter(validation)= %5d\t train= %s valid= %s test= %s [%.1f s] "
                     % (best_epoch + 1,
                        utils.format_metric(self.train_results[best_epoch]),
                        utils.format_metric(self.valid_results[best_epoch]),
                        utils.format_metric(self.test_results[best_epoch]),
                        self.time[1] - self.time[0]) + ','.join(self.metrics))
        best_test_score = utils.best_result(self.metrics[0], self.test_results)
        best_epoch = self.test_results.index(best_test_score)
        logging.info("Best Iter(test)= %5d\t train= %s valid= %s test= %s [%.1f s] "
                     % (best_epoch + 1,
                        utils.format_metric(self.train_results[best_epoch]),
                        utils.format_metric(self.valid_results[best_epoch]),
                        utils.format_metric(self.test_results[best_epoch]),
                        self.time[1] - self.time[0]) + ','.join(self.metrics))
        model.load_model()